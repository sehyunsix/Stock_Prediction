{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ssu36/tiger/Stock_Prediction/data/data_downloader.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/data/data_downloader.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39myfinance\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39myfm\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/data/data_downloader.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/data/data_downloader.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m yf\u001b[39m.\u001b[39mpdr_override()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/data/data_downloader.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m ticker_df_list \u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(data[\u001b[39m'\u001b[39m\u001b[39mTicker\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/data/data_downloader.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m price_data\u001b[39m=\u001b[39m{}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yfm\n",
    "from tqdm import tqdm\n",
    "yf.pdr_override()\n",
    "\n",
    "ticker_df_list =list(data['Ticker'].unique())\n",
    "price_data={}\n",
    "for ticker in ticker_df_list:\n",
    "    df = yf.download(ticker, interval='1d', period='3y')\n",
    "    price_data[ticker] = df\n",
    "    df.to_csv(f'stockPrice/{ticker}.csv')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# Set the path to the directory containing the CSV files\n",
    "PATH = '/home/ssu36/tiger/Stock_Prediction/data/stockPrice'\n",
    "\n",
    "# Get the list of CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(PATH) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty dictionary to store the dataframes\n",
    "dfs = {}\n",
    "\n",
    "# Iterate over each CSV file\n",
    "for file in tqdm(csv_files):\n",
    "  # Read the CSV file into a dataframe\n",
    "  df = pd.read_csv(os.path.join(PATH, file))\n",
    "  ticker_name =file.split('.')[0]\n",
    "  df[\"Ticker\"] = ticker_name\n",
    "  # Add the dataframe to the dictionary with the file name as the key\n",
    "  if len(df) == 755:\n",
    "    dfs[ticker_name] = df\n",
    "data = pd.concat(dfs.values(), ignore_index=True)\n",
    "# Print the dictionary of dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "# data= datasets.load_dataset('sehyun66/STOCKPRICE','NASDAQ_3y',split='train')\n",
    "# data = data.to_pandas()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_window(df,feature:list,window_size:int,predict_size:int,sliding_size:int):\n",
    "  ticker_number =len(df['Ticker'].unique())\n",
    "  total_day = len(df['Date'].unique())\n",
    "  window_number =int(total_day - (window_size+predict_size)/sliding_size+1)\n",
    "  feature_size = len(feature)\n",
    "\n",
    "  sequences = list()\n",
    "  for group in df.groupby('Ticker'):\n",
    "    sequences.append(group[1][feature])\n",
    "  sequences=np.array(sequences)\n",
    "\n",
    "  ## min_max trading\n",
    "  price , trade,sentiments =np.split(sequences,[4,5],axis=2)\n",
    "  trade , min_max_trading =min_max(trade)\n",
    "  price , min_max_list =min_max(price)\n",
    "  combine =np.concatenate([price,trade,sentiments],axis =2)\n",
    "\n",
    "  ## min_max another\n",
    "  result_list= []\n",
    "  for i in range(0,window_number):\n",
    "    a, b, c= np.split(combine,[i,i+window_size+predict_size],axis=1)\n",
    "    result_list.append(b)\n",
    "  result_array = np.array(result_list)\n",
    "  train ,vaild = np.split(result_array,[-1],axis=0)\n",
    "  # train_x,train_y=np.split(train.reshape(total_day%(window_size+predict_size)*ticker_number,window_size+predict_size,feature_size),[window_size],axis=1)\n",
    "  train_x,train_y=np.split(train.reshape((window_number-1)*ticker_number,window_size+predict_size,feature_size),[window_size],axis=1)\n",
    "  vaild_x,vaild_y=np.split(vaild.reshape(1*ticker_number,window_size+predict_size,feature_size),[window_size],axis=1)\n",
    "  print(train_x.shape,train_y.shape,vaild_x.shape,vaild_y.shape,len(min_max_list))\n",
    "  return train_x,train_y,vaild_x,vaild_y,min_max_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "feature = [ 'Open', 'High','Low','Close', 'Volume']\n",
    "\n",
    "sequences = list()\n",
    "for group in data.groupby('Ticker'):\n",
    "    sequences.append(group[1][feature])\n",
    "sequences=np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price , trade,sentiments =np.split(sequences,[4,5],axis=2)\n",
    "trade , min_max_trading =min_max(trade)\n",
    "price , min_max_list =min_max(price)\n",
    "combine =np.concatenate([price,trade,sentiments],axis =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_min_max(sequences,min_max):\n",
    "  original = []\n",
    "  for index,sequence in enumerate(sequences):\n",
    "    v_min =min_max[index][0]\n",
    "    v_max =min_max[index][1]\n",
    "    sequence_restored = (sequence) * (v_max - v_min) + v_min\n",
    "    original.append(sequence_restored)\n",
    "  return np.array(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_split(sequences,WINDOW_NUMBER,PREDICT_SIZE,WINDOW_SIZE,FEATURE_SIZE,TICKER_NUMBER):\n",
    "  original_list =[]\n",
    "  for i in range(0,WINDOW_NUMBER):\n",
    "    a, b, c= np.split(sequences,[i,i+WINDOW_SIZE+PREDICT_SIZE],axis=1)\n",
    "    original_list.append(b)\n",
    "  print(len(original_list))\n",
    "  result_array = np.array(original_list)\n",
    "  train ,vaild = np.split(result_array,[-1],axis=0)\n",
    "  train_x,train_y=np.split(train.reshape((WINDOW_NUMBER-1)*TICKER_NUMBER,WINDOW_SIZE+PREDICT_SIZE,FEATURE_SIZE),[WINDOW_SIZE],axis=1)\n",
    "  vaild_x,vaild_y=np.split(vaild.reshape(1*TICKER_NUMBER,WINDOW_SIZE+PREDICT_SIZE,FEATURE_SIZE),[WINDOW_SIZE],axis=1)\n",
    "  return train_x,train_y,vaild_x,vaild_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y,vaild_x,vaild_y = make_split(sequences,window_number,predict_size,window_size,feature_size,ticker_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y,vaild_x,vaild_y = make_split(combine,window_number,predict_size,window_size,feature_size,ticker_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssu36/anaconda3/envs/tiger/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_processing import Window_maker\n",
    "import datasets\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "data= datasets.load_dataset('sehyun66/STOCKPRICE','NASDAQ_3y',split='train'\n",
    "                            )\n",
    "data = data.to_pandas()\n",
    "window_size= 90\n",
    "predict_size= 15\n",
    "test_size = 15\n",
    "sliding_size=1\n",
    "window_maked = Window_maker(window_size,test_size,sliding_size,predict_size,data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 완료..\n"
     ]
    }
   ],
   "source": [
    "original, scaled ,min_max_list= window_maked.preprocess_window()\n",
    "# price , trade,sentiments =np.split(sequences,[4,5],axis=2)\n",
    "# trade , min_max_trading =min_max(trade)\n",
    "# price , min_max_list =min_max(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.swapaxes(original[0], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 1358496, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(x_data,y_data,y_original,target,window_maker,train = True):\n",
    "    class BaseDataset(Dataset):\n",
    "      def __init__(self, x_data, y_data):\n",
    "          x_data = np.swapaxes(x_data, 0, 1)\n",
    "          y_data = np.swapaxes(y_data, 0, 1)\n",
    "          label_data = np.swapaxes(y_original, 0, 1)\n",
    "          self.train = train\n",
    "          self.lable_data =torch.tensor(label_data[:,:,window_maker.feature.index(target)],dtype = torch.float32)\n",
    "          self.x_data = torch.tensor(x_data,dtype =torch.float32)\n",
    "          self.y_data = torch.tensor(y_data[:,:,window_maker.feature.index(target)],dtype = torch.float32)\n",
    "          self.min_max_list = torch.tensor(window_maker.min_max_list,dtype = torch.float32)\n",
    "      def __getitem__(self, index):\n",
    "          return self.x_data[:,index], self.y_data[:,index] ,self.lable_data[:,index] ,self.min_max_list[self.get_minmax_index(index)],index ,self.get_minmax_index(index)\n",
    "      def get_minmax_index(self,index):\n",
    "          if self.train == True:\n",
    "            index = index%(window_maked.ticker_number)\n",
    "          else:\n",
    "            index = index%(window_maker.ticker_number)\n",
    "          return index\n",
    "      def __len__(self):\n",
    "          return self.x_data.shape[0]\n",
    "    return BaseDataset(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "  train_x,train_y,vaild_x,vaild_y = scaled\n",
    "  trian_x_o,train_y_0,vaild_x_o,vaild_y_o = original\n",
    "\n",
    "  train_data = make_dataset(train_x,train_y,train_y_0,'Close',window_maked,train=True)\n",
    "  test_data =  make_dataset(vaild_x,vaild_y,vaild_y_o,'Close',window_maked,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True,drop_last=True)\n",
    " test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 90, 5]) torch.Size([64, 15]) torch.Size([64, 15]) torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "  train_x,train_y,train_y_o ,min_max_list,index, min_max_index= batch\n",
    "  print(train_x.shape,train_y.shape,train_y_o.shape,min_max_list.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 64, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(train_x,0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_min_max(sequences, min_max):\n",
    "  original = []\n",
    "  for index, sequence in tqdm(enumerate(sequences)):\n",
    "    v_min = min_max[index][0]\n",
    "    v_max = min_max[index][1]\n",
    "    sequence_restored = (sequence) * (v_max - v_min) + v_min\n",
    "    original.append(sequence_restored)\n",
    "    result = torch.stack(original)\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5900, 3.9500])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(min_max_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 667189,  424204,   31772, 1148769,  534079,   85506,  275788,  272712,\n",
       "        1163889, 1308429,  235974, 1201019,  640015,  182198,  559812,  486165,\n",
       "         625105,  894589, 1043157,  401873,  315855,  586384,  140125,  831902,\n",
       "        1351761, 1323146,  392330, 1057887,  905280, 1117382,  423205,  436705,\n",
       "         871084, 1193691,  608391,  697101, 1146275,   53598,   89673,  169000,\n",
       "          75987,  792669,  780190,  492949,  313071,  387208,  398759,  974736,\n",
       "         490803,  115744, 1081713,  274104, 1312472,  279437, 1276491,  428555,\n",
       "         118211,  778506,  835455,  897822,  586475,  573951,  923040,  502826])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 757, 1276, 1868, 1737,   79,   66,  244, 1440, 1905, 1197, 1014,  587,\n",
       "        1351,  638,  180, 1293, 1393, 1741,  789,  305, 1863, 1120, 1285,  998,\n",
       "        1809,  962, 1442,  567, 1752,  254,  277,  961, 1732, 1803, 1767,  765,\n",
       "        1379,  198, 2097,  256, 1227,  213,  550, 1669, 1215,  592, 1463,  720,\n",
       "        1659,  400,  897,  696,  968, 1757, 1299, 1355,  731, 1002,  279,  702,\n",
       "        1211, 1503,  288,  866])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 5, 90]), torch.Size([64, 15]), (1358496, 15, 5))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,train_y.shape,train_y_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(min_max_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Window_maker.inverse_min_max(train_y,min_max_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([110.1400, 110.3500, 109.2000, 108.4375, 106.8725, 106.6025, 104.5550,\n",
       "         104.2000, 102.7450, 105.7625, 102.0575, 103.8850, 102.2200,  99.1650,\n",
       "         100.3425]),\n",
       " tensor([110.1400, 110.3500, 109.2000, 108.4375, 106.8725, 106.6025, 104.5550,\n",
       "         104.2000, 102.7450, 105.7625, 102.0575, 103.8850, 102.2200,  99.1650,\n",
       "         100.3425]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2],train_y_o[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUSH CSV TO HUGGINGFACE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dataset = datasets.load_dataset('sehyun66/STOCKPRICE','NASDAQ_3y')\n",
    "data= pd.read_csv('NASDAQ_3y/stock_price_clean-train.csv',index_col=0)\n",
    "data.to_csv('NASDAQ_3y/stock_price_clean-train.csv',index=False)\n",
    "dataset.push_to_hub('sehyun66/STOCKPRICE','NASDAQ_3y')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
