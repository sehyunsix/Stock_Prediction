{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "from torchsummary import summary\n",
    "from TCN import TemporalConvNet\n",
    "import argparse\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset ,DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train setting\n",
    "DEVICE = 'cuda:0'\n",
    "IR = 0.1\n",
    "EPOCH =400\n",
    "DROPOUT=0.3\n",
    "PATIENCE =20\n",
    "BATCH_SIZE = 1024\n",
    "NUM_LAYERS =2\n",
    "SUFFLE = True\n",
    "\n",
    "input_size = 5\n",
    "num_channels =[80]*3\n",
    "kenel_size = 7\n",
    "output_size= 30\n",
    "dropout = 0.25\n",
    "\n",
    "\n",
    "WINDOW_SIZE  = 90\n",
    "PREDICT_SIZE = 15\n",
    "SLIDING_SIZE =1\n",
    "FEATURE_SIZE = 5\n",
    "BATCH_SIZE =64\n",
    "FULLLY_SIZE =128\n",
    "FEATURE = [ 'Open', 'High','Low','Close', 'Volume']\n",
    "TARGET = 'Close'\n",
    "TICKER_NUMBER =2743\n",
    "TOTAL_DAY = 166\n",
    "WINDOW_NUMBER =int(TOTAL_DAY - (WINDOW_SIZE+PREDICT_SIZE)/SLIDING_SIZE+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
    "        super(TCNModel, self).__init__()\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.linear.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.tcn(x)\n",
    "        return self.linear(y1[:, :, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data= pd.read_csv('../../../data/stockPrice/NASDAQ.csv')\n",
    "data.columns = ['Date', 'Ticker', 'Open', 'High','Low', 'Close', 'Volume','sell','buy' ]\n",
    "\n",
    "\n",
    "\n",
    "def min_max(sequences):\n",
    "  results = sequences.copy()\n",
    "  v_min =results.min()\n",
    "  v_max =results.max()\n",
    "  new_min =0\n",
    "  new_max =1\n",
    "  min_max=[]\n",
    "  for index,sequence in enumerate(results):\n",
    "    v_min =sequence.min()\n",
    "    v_max =sequence.max()\n",
    "    v_p = (sequence - v_min)/(v_max - v_min)*(new_max - new_min) + new_min\n",
    "    min_max.append([v_min,v_max])\n",
    "    results[index] = v_p\n",
    "  return results, min_max\n",
    "\n",
    "def inverse_min_max(sequences,min_max):\n",
    "  original = []\n",
    "  for index,sequence in enumerate(sequences):\n",
    "    v_min =min_max[index][0]\n",
    "    v_max =min_max[index][1]\n",
    "    sequence_restored = (sequence) * (v_max - v_min) + v_min\n",
    "    original.append(sequence_restored)\n",
    "  return np.array(original)\n",
    "\n",
    "def preprocess_lstm(df):\n",
    "  sequences = list()\n",
    "  for group in df.groupby('Ticker'):\n",
    "    sequences.append(group[1][FEATURE])\n",
    "  sequences=np.array(sequences)\n",
    "\n",
    "  ## min_max trading\n",
    "  price , trade,sentiments =np.split(sequences,[4,5],axis=2)\n",
    "  trade , min_max_trading =min_max(trade)\n",
    "  price , min_max_list =min_max(price)\n",
    "  combine =np.concatenate([price,trade,sentiments],axis =2)\n",
    "\n",
    "  ## min_max another\n",
    "\n",
    "  ## min_max another\n",
    "  result_list= []\n",
    "  for i in range(0,WINDOW_NUMBER):\n",
    "    a, b, c= np.split(combine,[i,i+WINDOW_SIZE+PREDICT_SIZE],axis=1)\n",
    "    result_list.append(b)\n",
    "  result_array = np.array(result_list)\n",
    "  print(166//(WINDOW_SIZE+PREDICT_SIZE))\n",
    "  train ,vaild = np.split(result_array,[166%(WINDOW_SIZE+PREDICT_SIZE)],axis=0)\n",
    "  train_x,train_y=np.split(train.reshape(166%(WINDOW_SIZE+PREDICT_SIZE)*TICKER_NUMBER,WINDOW_SIZE+PREDICT_SIZE,FEATURE_SIZE),[WINDOW_SIZE],axis=1)\n",
    "  vaild_x,vaild_y=np.split(vaild.reshape(1*TICKER_NUMBER,WINDOW_SIZE+PREDICT_SIZE,FEATURE_SIZE),[WINDOW_SIZE],axis=1)\n",
    "  return train_x,train_y,vaild_x,vaild_y,min_max_list\n",
    "\n",
    "\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, target):\n",
    "        self.x_data = torch.tensor(x_data,dtype =torch.float32)\n",
    "        self.y_data = torch.tensor(y_data[:,FEATURE.index(target),:],dtype = torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_data.shape[0]\n",
    "train_x,train_y,vaild_x,vaild_y,min_max_list = preprocess_lstm(data)\n",
    "\n",
    "def swap_axes(arr):\n",
    "    return np.swapaxes(arr, 1, 2)\n",
    "train_x = swap_axes(train_x)\n",
    "train_y = swap_axes(train_y)\n",
    "vaild_x = swap_axes(vaild_x)\n",
    "vaild_y = swap_axes(vaild_y)\n",
    "train_x.shape,train_y.shape,vaild_x.shape,vaild_y.shape,len(min_max_list)\n",
    "\n",
    "train_data = BaseDataset(train_x,train_y,TARGET)\n",
    "test_data =  BaseDataset(vaild_x,vaild_y,TARGET)\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True,drop_last=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True,drop_last=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167323, 5, 15)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126178, 5, 90)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.reshape(126178,5,90).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN_trainer:\n",
    "    def __init__(self,model, train_loader, test_loader,num_epochs = None, lr = None,batch_size=BATCH_SIZE, verbose = 1, patience=None):\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader =test_loader\n",
    "        self.verbose = verbose\n",
    "        self.patience =patience\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.criterion = nn.MSELoss().to(self.device)\n",
    "        self.optimizer =  optim.Adam(model.parameters(), lr = lr)\n",
    "        self.scheduler =   optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min')\n",
    "        self.nb_epochs = num_epochs\n",
    "        self.train_hist  = np.zeros(self.nb_epochs)\n",
    "        self.vaild_hist =[]\n",
    "\n",
    "    def train(self):\n",
    "        config = {\n",
    "        \"model\":'TCN',\n",
    "        \"learning_rate\": IR,\n",
    "        \"epochs\": EPOCH,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"shuffle\":SUFFLE,\n",
    "        'verbose':1,\n",
    "        'patience':PATIENCE,\n",
    "        'dropout':DROPOUT,\n",
    "        'target':TARGET,\n",
    "        'feature_columns':FEATURE,\n",
    "        \"NUM_CHANNELS\":num_channels,\n",
    "        'KERNEL':kenel_size,\n",
    "\n",
    "        }\n",
    "        run = wandb.init(project =\"LSTM\",config=config)\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        for epoch in range(self.nb_epochs):\n",
    "            avg_cost = 0\n",
    "            total_batch = len(self.train_loader)\n",
    "            for batch_idx, samples in enumerate(self.train_loader):\n",
    "                x_train, y_train = samples\n",
    "                x_train =x_train.cuda()\n",
    "                y_train =y_train.cuda()\n",
    "                outputs = self.model(x_train)\n",
    "                loss = self.criterion(outputs, y_train)\n",
    "                self.optimizer.zero_grad()\n",
    "                ##loss\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                avg_cost += loss/total_batch\n",
    "                ##정확도 계산\n",
    "                predict, label = outputs.clone().detach(),y_train.clone().detach()\n",
    "                predict = inverse_min_max(predict.to('cpu').numpy(),min_max_list)\n",
    "                label =  inverse_min_max(label.to('cpu').numpy(),min_max_list)\n",
    "                score = self.MAE(predict,label)\n",
    "                acc = self.accuracy(label,predict)\n",
    "                wandb.log({\"Training Loss\": loss.item()})\n",
    "            self.train_hist[epoch] = avg_cost\n",
    "            if epoch % self.verbose == 0:\n",
    "                total_loss, score,acc =self.vaild()\n",
    "                print('Epoch:', '%04d' % (epoch), 'train loss :', '{:.4f}'.format(avg_cost))\n",
    "                print('vaild_loss:', '{:.4f}'.format (total_loss), 'MAE :', '{:.4f}'.format(score),'Accuarcy :', '{:.4f}'.format(acc))\n",
    "                wandb.log({\"Evaluation Loss\": loss.item()})\n",
    "                wandb.log({\"Evaluation MAE\": score.item()})\n",
    "                wandb.log({\"Evaluation Accuracy\": acc.item()})\n",
    "                self.vaild_hist.append({\"vaild_loss\":total_loss ,\"vaild_score\":score,\"vaild_accuracy\":acc,\"epoch\":epoch})\n",
    "                self.scheduler.step(total_loss)\n",
    "        # patience번째 마다 early stopping 여부 확인\n",
    "            if (epoch % self.patience == 0) & (epoch != 0):\n",
    "                # loss가 커졌다면 early stop\n",
    "                index =int(epoch/self.patience)\n",
    "                if index> 1:\n",
    "                    print((self.vaild_hist[index-1]['vaild_loss'] ,  self.vaild_hist[index]['vaild_loss'])   )\n",
    "                    if self.vaild_hist[index-1]['vaild_loss']<self.vaild_hist[index]['vaild_loss']:\n",
    "                        print('\\n Early Stopping')\n",
    "                        break\n",
    "                    else:\n",
    "                        print('model was saved')\n",
    "                        torch.save(self.model,\"best-model.pt\")\n",
    "    def vaild(self):\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = []\n",
    "            avg_cost = 0\n",
    "            score = 0\n",
    "            acc = 0\n",
    "            total_batch= len(test_dataloader)\n",
    "            for batch_idx, samples in enumerate(self.test_loader):\n",
    "                x_test, y_test = samples\n",
    "                x_test =x_test.cuda()\n",
    "                y_test =y_test.cuda()\n",
    "                outputs = self.model(x_test)\n",
    "                loss = self.criterion(outputs, y_test)\n",
    "                avg_cost += loss\n",
    "                predict = inverse_min_max(outputs.to('cpu'),min_max_list)\n",
    "                y_test =  inverse_min_max(y_test.to('cpu'),min_max_list)\n",
    "                score += self.MAE(predict,y_test)\n",
    "                acc += self.accuracy(y_test,predict)\n",
    "        total_loss = avg_cost/total_batch\n",
    "        score = score/len(self.test_loader)\n",
    "        acc = acc/len(self.test_loader)\n",
    "        self.model.train()\n",
    "        return total_loss,score,acc\n",
    "\n",
    "    def MAE(self,true, pred):\n",
    "         return np.mean(np.abs(true-pred))\n",
    "    def accuracy(self,true, pred):\n",
    "        return (1-np.mean(np.abs((true-pred)/true)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssu36/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "model = TCNModel(input_size=5 ,num_channels=num_channels,output_size=PREDICT_SIZE,kernel_size=kenel_size, dropout=0.25)\n",
    "trainer = TCN_trainer(model,train_dataloader,test_dataloader,num_epochs=EPOCH,lr= IR,batch_size=BATCH_SIZE,patience=PATIENCE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/wandb/run-20231124_025716-2brcmh0m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sehyunai/LSTM/runs/2brcmh0m' target=\"_blank\">glowing-planet-109</a></strong> to <a href='https://wandb.ai/sehyunai/LSTM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sehyunai/LSTM' target=\"_blank\">https://wandb.ai/sehyunai/LSTM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sehyunai/LSTM/runs/2brcmh0m' target=\"_blank\">https://wandb.ai/sehyunai/LSTM/runs/2brcmh0m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 train loss : 118108.3438\n",
      "vaild_loss: 0.0244 MAE : 2.3470 Accuarcy : 0.8917\n",
      "Epoch: 0001 train loss : 0.0532\n",
      "vaild_loss: 0.0259 MAE : 2.3142 Accuarcy : 0.8713\n",
      "Epoch: 0002 train loss : 0.0259\n",
      "vaild_loss: 0.0202 MAE : 2.1097 Accuarcy : 0.8754\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN_test.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN_test.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN_test.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "\u001b[1;32m/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN_test.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN_test.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m x_train \u001b[39m=\u001b[39mx_train\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN_test.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m y_train \u001b[39m=\u001b[39my_train\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN_test.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN_test.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(outputs, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN_test.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN_test.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN_test.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN_test.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     y1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtcn(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B203.253.25.176/home/ssu36/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN_test.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(y1[:, :, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN.py:63\u001b[0m, in \u001b[0;36mTemporalConvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/tiger/Stock_Prediction/models/TimeSeries/TCN/TCN.py:43\u001b[0m, in \u001b[0;36mTemporalBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 43\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(x)\n\u001b[1;32m     44\u001b[0m     res \u001b[39m=\u001b[39m x \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample(x)\n\u001b[1;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out \u001b[39m+\u001b[39m res)\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/modules/module.py:1557\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1553\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mforward pre-hook must return None or a tuple \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1554\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00margs_kwargs_result\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1555\u001b[0m             )\n\u001b[1;32m   1556\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1557\u001b[0m     args_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39;49m, args)\n\u001b[1;32m   1558\u001b[0m     \u001b[39mif\u001b[39;00m args_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1559\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(args_result, \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:67\u001b[0m, in \u001b[0;36mWeightNorm.__call__\u001b[0;34m(self, module, inputs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, module: Module, inputs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39msetattr\u001b[39m(module, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_weight(module))\n",
      "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:26\u001b[0m, in \u001b[0;36mWeightNorm.compute_weight\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m     24\u001b[0m g \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_g\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_v\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[39mreturn\u001b[39;00m _weight_norm(v, g, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdim)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-violet-108</strong> at: <a href='https://wandb.ai/sehyunai/LSTM/runs/gqto0wrq' target=\"_blank\">https://wandb.ai/sehyunai/LSTM/runs/gqto0wrq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231124_025120-gqto0wrq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X , y = torch.Tensor(),torch.Tensor()\n",
    "for batch_idx, samples in enumerate(train_dataloader):\n",
    "    x_train, y_train = samples\n",
    "    X =x_train.cuda()\n",
    "    y =y_train.cuda()\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "output =model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 30])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
